"""
Phase 2å®Ÿè£…ã®å‹•ä½œç¢ºèªã‚¹ã‚¯ãƒªãƒ—ãƒˆ

Phase 2ã®æ–°æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ:
- FullContextMemoryBank (Valueä¿å­˜å®Œå…¨å®Ÿè£…)
- s1/s2/s3å…¨éšå±¤ã¸ã®Multi-Referenceé©ç”¨
- éšå±¤é–“ãƒ¡ãƒ¢ãƒªå…±æœ‰

ä½¿ç”¨æ–¹æ³•:
    python examples/test_phase2.py
"""

import torch
import sys
sys.path.insert(0, '/workspace/LIC-HPCM-MultiRef')


def test_full_memory_bank():
    """FullContextMemoryBankã®ãƒ†ã‚¹ãƒˆ"""
    print("="*60)
    print("Test 1: FullContextMemoryBank (Value Storage)")
    print("="*60)
    
    from src.layers.multi_ref_phase2 import FullContextMemoryBank
    
    memory_bank = FullContextMemoryBank(
        context_dim=640,
        max_refs=4,
        compress_ratio=4,
        value_resolution=8,
        num_heads=8,
        enable_value_storage=True
    ).cuda()
    
    B, C, H, W = 2, 640, 16, 16
    
    print(f"\n[1] Testing with value storage (B={B}, C={C}, H={H}, W={W})...")
    
    # ãƒªã‚»ãƒƒãƒˆ
    memory_bank.reset()
    print("âœ“ Memory reset")
    
    # ã‚¹ãƒ†ãƒƒãƒ—1-3: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¿½åŠ 
    for step in range(1, 4):
        context = torch.randn(B, C, H, W).cuda()
        memory_bank.add_to_memory(context)
        print(f"âœ“ Added context to memory (step {step})")
    
    # Valueå–å¾—ãƒ†ã‚¹ãƒˆ
    current_context = torch.randn(B, C, H, W).cuda()
    attn_weights, topk_indices, valid = memory_bank.query_memory(current_context, k=2)
    
    print(f"\n[2] Query and retrieve values:")
    print(f"  - Attention weights: {attn_weights[0].cpu().numpy()}")
    print(f"  - Top-k indices: {topk_indices[0].cpu().numpy()}")
    
    # Valueå¾©å…ƒ
    ref_contexts = memory_bank.retrieve_values(topk_indices, (H, W))
    if ref_contexts is not None:
        print(f"  - Retrieved contexts shape: {ref_contexts.shape}")
        print(f"âœ“ Value retrieval successful")
    
    # Fusion
    fused = memory_bank.fuse_references(current_context, ref_contexts, attn_weights)
    print(f"  - Fused context shape: {fused.shape}")
    print(f"âœ“ Fusion successful")
    
    # Forwardçµ±åˆãƒ†ã‚¹ãƒˆ
    enhanced = memory_bank.forward(current_context, k=2)
    print(f"  - Enhanced context shape: {enhanced.shape}")
    print(f"âœ“ Full forward pass successful")
    
    print("\nâœ… Test 1 PASSED\n")


def test_phase2_model():
    """Phase 2ãƒ¢ãƒ‡ãƒ«ã®åŸºæœ¬ãƒ†ã‚¹ãƒˆ"""
    print("="*60)
    print("Test 2: HPCM_MultiRef_Phase2 Basic Forward")
    print("="*60)
    
    from src.models.multiref.phase2 import HPCM_MultiRef_Phase2
    
    x = torch.randn(1, 3, 256, 256).cuda()
    
    print("\n[1] Testing Phase 2 with full multi-reference...")
    model_phase2 = HPCM_MultiRef_Phase2(
        M=320,
        N=256,
        enable_multiref=True,
        max_refs_s1=2,
        max_refs_s2=3,
        max_refs_s3=4,
        topk_refs_s1=1,
        topk_refs_s2=2,
        topk_refs_s3=2,
        enable_hierarchical_transfer=False  # Phase 2åŸºæœ¬ç‰ˆ
    ).cuda()
    model_phase2.eval()
    
    with torch.no_grad():
        output = model_phase2(x, training=False)
    
    print(f"âœ“ Output x_hat shape: {output['x_hat'].shape}")
    print(f"âœ“ y likelihood shape: {output['likelihoods']['y'].shape}")
    print(f"âœ“ z likelihood shape: {output['likelihoods']['z'].shape}")
    
    print("\n[2] Testing Baseline mode...")
    model_baseline = HPCM_MultiRef_Phase2(
        M=320,
        N=256,
        enable_multiref=False
    ).cuda()
    model_baseline.eval()
    
    with torch.no_grad():
        output_baseline = model_baseline(x, training=False)
    
    print(f"âœ“ Baseline output shape: {output_baseline['x_hat'].shape}")
    
    print("\nâœ… Test 2 PASSED\n")


def test_all_scales():
    """å…¨éšå±¤ã®Multi-Referenceãƒ†ã‚¹ãƒˆ"""
    print("="*60)
    print("Test 3: Multi-Reference on All Scales (s1/s2/s3)")
    print("="*60)
    
    from src.models.multiref.phase2 import HPCM_MultiRef_Phase2
    
    x = torch.randn(1, 3, 128, 128).cuda()
    
    configs = [
        {
            "name": "Phase 2 - Conservative",
            "max_refs_s1": 2, "max_refs_s2": 2, "max_refs_s3": 3,
            "topk_refs_s1": 1, "topk_refs_s2": 1, "topk_refs_s3": 2
        },
        {
            "name": "Phase 2 - Balanced",
            "max_refs_s1": 2, "max_refs_s2": 3, "max_refs_s3": 4,
            "topk_refs_s1": 1, "topk_refs_s2": 2, "topk_refs_s3": 2
        },
        {
            "name": "Phase 2 - Aggressive",
            "max_refs_s1": 3, "max_refs_s2": 4, "max_refs_s3": 6,
            "topk_refs_s1": 2, "topk_refs_s2": 3, "topk_refs_s3": 3
        }
    ]
    
    for i, config in enumerate(configs):
        print(f"\n[{i+1}] Testing {config['name']}...")
        config_copy = {k: v for k, v in config.items() if k != "name"}
        
        model = HPCM_MultiRef_Phase2(
            M=320, N=256,
            enable_multiref=True,
            **config_copy
        ).cuda()
        model.eval()
        
        with torch.no_grad():
            output = model(x, training=False)
        
        print(f"âœ“ {config['name']} successful")
    
    print("\nâœ… Test 3 PASSED\n")


def test_training_mode():
    """è¨“ç·´ãƒ¢ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆ"""
    print("="*60)
    print("Test 4: Training Mode with Full Multi-Reference")
    print("="*60)
    
    from src.models.multiref.phase2 import HPCM_MultiRef_Phase2
    
    x = torch.randn(2, 3, 128, 128).cuda()
    
    model = HPCM_MultiRef_Phase2(
        M=320,
        N=256,
        enable_multiref=True,
        max_refs_s1=2,
        max_refs_s2=3,
        max_refs_s3=4
    ).cuda()
    model.train()
    
    print("\n[1] Forward pass in training mode...")
    output = model(x, training=True)
    
    print(f"âœ“ Output x_hat shape: {output['x_hat'].shape}")
    
    # Lossè¨ˆç®—
    print("\n[2] Computing loss...")
    mse_loss = torch.nn.functional.mse_loss(output['x_hat'], x)
    rate_loss = output['likelihoods']['y'].log().sum() + output['likelihoods']['z'].log().sum()
    total_loss = mse_loss - rate_loss
    
    print(f"âœ“ MSE Loss: {mse_loss.item():.4f}")
    print(f"âœ“ Rate Loss: {rate_loss.item():.4f}")
    print(f"âœ“ Total Loss: {total_loss.item():.4f}")
    
    # Backward
    print("\n[3] Backward pass...")
    total_loss.backward()
    print("âœ“ Backward successful")
    
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°æ¯”è¼ƒ
    print("\n[4] Model complexity...")
    param_count = sum(p.numel() for p in model.parameters())
    print(f"âœ“ Total parameters: {param_count:,}")
    
    print("\nâœ… Test 4 PASSED\n")


def test_memory_efficiency():
    """ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã®ãƒ†ã‚¹ãƒˆ"""
    print("="*60)
    print("Test 5: Memory Efficiency Comparison")
    print("="*60)
    
    from src.models.multiref.phase2 import HPCM_MultiRef_Phase2
    
    x = torch.randn(1, 3, 256, 256).cuda()
    
    configs = [
        {"compress_ratio": 2, "value_resolution": 16, "name": "High Quality"},
        {"compress_ratio": 4, "value_resolution": 8, "name": "Balanced"},
        {"compress_ratio": 8, "value_resolution": 4, "name": "Memory Efficient"}
    ]
    
    for i, config in enumerate(configs):
        print(f"\n[{i+1}] Testing {config['name']}...")
        
        torch.cuda.reset_peak_memory_stats()
        
        model = HPCM_MultiRef_Phase2(
            M=320, N=256,
            enable_multiref=True,
            max_refs_s1=2, max_refs_s2=3, max_refs_s3=4,
            compress_ratio=config['compress_ratio'],
            value_resolution=config['value_resolution']
        ).cuda()
        model.eval()
        
        with torch.no_grad():
            output = model(x, training=False)
        
        if torch.cuda.is_available():
            memory_allocated = torch.cuda.memory_allocated() / 1024**2
            memory_peak = torch.cuda.max_memory_allocated() / 1024**2
            print(f"  - Memory allocated: {memory_allocated:.2f} MB")
            print(f"  - Peak memory: {memory_peak:.2f} MB")
        
        print(f"âœ“ {config['name']} config tested")
    
    print("\nâœ… Test 5 PASSED\n")


def main():
    """å…¨ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("\n" + "="*60)
    print("HPCM Multi-Reference Phase 2 - Test Suite")
    print("="*60 + "\n")
    
    try:
        test_full_memory_bank()
        test_phase2_model()
        test_all_scales()
        test_training_mode()
        test_memory_efficiency()
        
        print("="*60)
        print("ğŸ‰ ALL PHASE 2 TESTS PASSED!")
        print("="*60)
        print("\nPhase 2å®Ÿè£…ãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™ã€‚")
        print("\nä¸»ãªæ”¹å–„ç‚¹:")
        print("âœ“ Valueä¿å­˜æ©Ÿèƒ½ã®å®Œå…¨å®Ÿè£…")
        print("âœ“ s1/s2/s3å…¨éšå±¤ã¸ã®Multi-Referenceé©ç”¨")
        print("âœ“ ã‚ˆã‚Šæ´—ç·´ã•ã‚ŒãŸattentionæ©Ÿæ§‹")
        print("âœ“ ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–ã‚ªãƒ—ã‚·ãƒ§ãƒ³")
        print("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print("1. Phase 1 vs Phase 2 ã®æ€§èƒ½æ¯”è¼ƒ")
        print("2. éšå±¤é–“ãƒ¡ãƒ¢ãƒªå…±æœ‰ã®åŠ¹æœæ¤œè¨¼")
        print("3. å®Ÿãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®è©•ä¾¡")
        
    except Exception as e:
        print("\n" + "="*60)
        print("âŒ TEST FAILED")
        print("="*60)
        print(f"\nError: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == "__main__":
    import sys
    sys.exit(main())
